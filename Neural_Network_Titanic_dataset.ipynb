{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69b32db9",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "Implementing the logistic regression unit, a single-neuron neural network.\n",
    "\n",
    "Write an alternative activation function, i.e., replace the sigmoid non-linearity with ReLu or tan, and then use Log Loss Function and code to do stochastic gradient descent (SGD) for optimization.\n",
    "\n",
    "Implementing as a set of functions is ideal.\n",
    "\n",
    "Using any Titanic dataset for a classification task.\n",
    "\n",
    "Providing the results' accuracy and F1 score is the last step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13f0cc2",
   "metadata": {},
   "source": [
    "### Importing packages required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a34decbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2d8f47",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8b8dcac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3afbb22",
   "metadata": {},
   "source": [
    "### Defining the ReLU activation function using pandas and numpy package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d6dc2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_function(z):\n",
    "    return np.maximum(0, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6bb438",
   "metadata": {},
   "source": [
    "### The Log Loss function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cccee270",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_loss_function(y_true, y_predict):\n",
    "    return -((y_true * np.log(y_predict)) + ((1 - y_true) * np.log(1 - y_predict)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2a52bd",
   "metadata": {},
   "source": [
    "### The function for stochastic gradient descent (SGD) optimization is defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61753374",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd_function(X, y_true, weights_generated, rate_of_learning):\n",
    "    y_pred = relu_function(np.dot(X, weights_generated))\n",
    "    error = y_pred - y_true\n",
    "    gradient = np.dot(X.T, error) / len(X)\n",
    "    weights_generated -= rate_of_learning * gradient\n",
    "    return weights_generated\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba425b3",
   "metadata": {},
   "source": [
    "### Create the training function for the logistic regression model with SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fcc6552",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(X, y, activation_function=relu_function, rate_of_learning=0.1, epochs=100):\n",
    "    X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "\n",
    "    weights_generated = np.zeros(X.shape[1])\n",
    "    \n",
    "    # Looping over the specified number of epochs\n",
    "    for epoch in range(epochs):\n",
    "        # Looping over each training example\n",
    "        for i in range(X.shape[0]):\n",
    "            # Performing SGD update\n",
    "            weights_generated = sgd_function(X[i], y[i], weights_generated, rate_of_learning)\n",
    "    \n",
    "    # Returning the learned weights\n",
    "    return weights_generated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ae3bdc",
   "metadata": {},
   "source": [
    "### Checking how many null and NaN are there in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4c55048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6eaa3dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07308bb",
   "metadata": {},
   "source": [
    "### Performing data wrangling\n",
    "\n",
    "1. Dropping non-relevant columns\n",
    "2. Convert categorical variables (ones with different categories) to one-hot encoding (labeling them)\n",
    "3. Filling missing values with mean (average values)\n",
    "4. Spliting the dataset into features and labels\n",
    "5. Scaling the features\n",
    "6. Spliting the titanic dataset into training and testing sets (80% and 20% respectively)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b241ec73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
    "\n",
    "df = pd.get_dummies(df, columns=['Sex', 'Embarked'])\n",
    "\n",
    "df = df.fillna(df.mean())\n",
    "\n",
    "X = df.drop('Survived', axis=1).values\n",
    "y = df['Survived'].values\n",
    "\n",
    "X = (X - X.mean()) / X.std()\n",
    "\n",
    "np.random.seed(42)\n",
    "idx = np.arange(X.shape[0])\n",
    "np.random.shuffle(idx)\n",
    "split_idx = int(X.shape[0] * 0.8)\n",
    "X_train, X_test = X[idx[:split_idx]], X[idx[split_idx:]]\n",
    "y_train, y_test = y[idx[:split_idx]], y[idx[split_idx:]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528b51f2",
   "metadata": {},
   "source": [
    "### checking if the no. of columns of the train and test data is same or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ec3c7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(179, 10)\n",
      "(179,)\n",
      "(712, 10)\n",
      "(712,)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "\n",
    "print(y_test.shape)\n",
    "\n",
    "print(X_train.shape)\n",
    "\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb78b8be",
   "metadata": {},
   "source": [
    "### Training this logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "349b6642",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_generated = logistic_regression(X_train, y_train, activation_function=relu_function, rate_of_learning=0.1, epochs=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09130cd1",
   "metadata": {},
   "source": [
    "### Making predictions on the test set using Numpy package and using ReLu activation function instead of sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e6c0399",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.hstack((np.ones((X_test.shape[0], 1)), X_test))\n",
    "y_pred = np.round(relu_function(np.dot(X_test, weights_generated)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9159755",
   "metadata": {},
   "source": [
    "### Calculating accuracy and F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98d121c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "104\n",
      "10\n",
      "32\n",
      "0.7653631284916201\n",
      "Accuracy: 0.7653631284916201\n",
      "F1 Score: 0.611111111111111\n"
     ]
    }
   ],
   "source": [
    "TP = np.sum((y_test == 1) & (y_pred == 1))\n",
    "print(TP)\n",
    "TN = np.sum((y_test == 0) & (y_pred == 0))\n",
    "print(TN)\n",
    "FP = np.sum((y_test == 0) & (y_pred == 1))\n",
    "print(FP)\n",
    "FN = np.sum((y_test == 1) & (y_pred == 0))\n",
    "print(FN)\n",
    "\n",
    "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "print(accuracy)\n",
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "f1 = 2 * precision * recall / (precision + recall)\n",
    "print('Accuracy:', accuracy)\n",
    "print('F1 Score:', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977405de",
   "metadata": {},
   "source": [
    "### This model is built with the accuracy of 76.5% and F1 score of 0.61. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc72279d",
   "metadata": {},
   "source": [
    "### some inferences drawn from this model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5e4a52",
   "metadata": {},
   "source": [
    "The Titanic dataset is a well-known example of a binary classification issue, where the objective is to predict a passenger's likelihood of survival based on characteristics like age, gender, ticket class, etc. Using this dataset, predictions can be made using a single neural network model. These are some conclusions that can be made using a single Titanic dataset neural network model:\n",
    "\n",
    "The weights gained by the neural network can be used to determine which features are most crucial for predicting survival. For instance, the neural network might discover that having a higher ticket class and being female are both significant predictors of survival.\n",
    "\n",
    "Relationships that are not linear: Unlike linear models like logistic regression, the neural network may learn non-linear relationships between the features and the target variable. The neural network might discover, for instance, that having a high ticket class and being young are important predictors of survival, which may not be clear from a simple linear relationship.\n",
    "\n",
    "Overfitting: A neural network that has been trained for a long time or too intricately may overfit the training set and underperform when presented with fresh data. Comparing the model's performance on the training and validation sets can reveal this. The model may be overfitting if it performs significantly better on the training set than the validation set.\n",
    "\n",
    "Generalization: Even if the distribution of the incoming data is slightly different, a neural network that has been trained successfully can nevertheless adapt well to it. By assessing the model on a held-out test set that wasn't used during training, this can be verified.\n",
    "\n",
    "Ultimately, a single neural network model can offer insightful information on the connections between the features and the goal variable as well as the model's generalization capabilities. Yet it's vital to remember that neural networks have a tendency to overfit and don't always produce outcomes that are easy to understand."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
